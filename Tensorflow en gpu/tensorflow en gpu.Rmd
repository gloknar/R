---
title: "Entrenamiento de redes neuronales en GPU"
author: "Adam Casas"
date: "22/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Documento codificado en UTF-8.

<br>


# Instalar TensorFlow

Resulta que TensorFlow __versión 2.1__ en adelante requiere de __Cuda 10.1__, y no Cuda 11.1 como yo pensaba. TensorFlow  V2.1 y en adelante ya incorporan tanto la versión para CPU como la versión para GPU, lo que significa que basta con instalarte `library(keras)` y `library(tensorflow)` para usar la GPU (nada de usar `tensorflow::install_tensorflow(version = "gpu")`, como dicen en los tutoriales obsoletos de internet).

Bueno, además de esas librerías en R, tienes que descargarte, como ya dije, Cuda 10.1. Además, descárgate la librería cuDNN más actualizada, pero la versión para Cuda 10.1. Cuda sirve para computación en GPU en general, pero para redes neuronales, necesitas las librerías cuDNN.

Creo que también tienes que instalarte Anaconda.

Yo gasto la versión de TensorFlow V`tensorflow::tf_version()`

¿Por qué no te van las redes en la GPU? Cuando defines la red neuronal (lo de `modelo = layer_conv_2d()` y tal), te saltará un error de que TensorFlow no ha podido encontrar los dlls `cudart64_101.dll` (fíjate, el 101 hace referencia a Cuda 10.1) o algo así, e ídem para los dlls de `cudNN64_8.dll` (cuDNN 8.0.4). Te descargas el Cuda development toolkit 10.1, te descargas las librerías cuDNN más actualizadas para Cuda 10.1, las mueves a la carpeta C:/Archivos de programa/Nvidia GPU Computing Toolkit/Cuda/v10.1/bin, lib e include, y vuelves a probar.

¿Que sigue igual? Pues añades la carpeta bin (y/o las otras 2) a la variable de entorno: PATH. Puedes hacerlo fácilmente desde configuración avanzada del sistema-> Variables de entorno.

# Al lío

Vamos a entrenar una red para que nos clasifique imágenes a color. El dataset a usar es cifar10 (el 10 hace referencia a que hay 10 tipos de imágenes: camión, coche, moto... etc)

```{r}
############################
# Ejemplo para clasificar imágenes a color (dataset cifar10). Sacado de https://rpubs.com/HeatWave2019/537744


# Primero cargamos keras
library(keras)

#Cargamos ahora el dataset MNIST
dataset_guapo <- dataset_cifar10()


# Con las fotos en blanco y negro de MNIST había que hacer este paso, pero
# parece ser que para imágenes a color, puedes pasárselas directamente a la red
# neuronal si su capa de entrada es de tipo layer_conv_2d():
#
# str(dataset_guapo)
# dim(dataset_guapo$train$x)
# dim(dataset_guapo$test$x)
# 
# dataset_guapo$train$x <- array_reshape(dataset_guapo$train$x, dim = c(60000, 28*28), order = "F")
# 
# dataset_guapo$test$x  <- array_reshape(dataset_guapo$test$x, dim = c(10000, 28*28), order = "F")
# 




# Pasamos las clases a codificación one-hot con to_categorical():

dim(dataset_guapo$train$y)
dim(dataset_guapo$test$y)

dataset_guapo$train$y <- to_categorical(dataset_guapo$train$y, num_classes = 10)

dataset_guapo$test$y <- to_categorical(dataset_guapo$test$y, num_classes = 10)




# Normalizamos la profundidad de color de los píxeles al dividirlos por su valor
# máximo (el color en estas fotos está codificado en 8 bits=256 valores,
# incluyendo el 0, luego el valor máximo será 255). Con esto normalizamos los píxeles del rango [0,255] al rango [0,1]

max(dataset_guapo$train$x)
max(dataset_guapo$test$x)


dataset_guapo$train$x <- dataset_guapo$train$x/255
dataset_guapo$test$x <- dataset_guapo$test$x/255





# Definimos el modelo con keras_model_sequential() y los comandos de la familia
# layer_(). Activación "softmax" para la capa de salida; activación "relu" para
# el resto:


modelo = keras_model_sequential()

modelo %>%
  # Start with hidden 2D CNN layer 
  layer_conv_2d( filters = 32, kernel_size = c(3,3), padding = "same", input_shape = c(32, 32, 3) ) %>%
  layer_activation("relu") %>%
  # Second hidden layer
  layer_conv_2d(filters  = 32, kernel_size = c(3,3)) %>%
  layer_activation("relu") %>%
  # Use max pooling
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.25) %>%
  # 2 additional hidden 2D CNN layers
  layer_conv_2d(filters = 32, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("relu") %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3)) %>%
  layer_activation("relu") %>%
  # Use max pooling 
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.25) %>%
  # Flatten max filtered output into feature vector
  layer_flatten() %>%
  # and feed into dense layer
  layer_dense(512) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5) %>%
  # Outputs from dense layer are projected onto 10 unit output layer
  layer_dense(10) %>%
  layer_activation("softmax")






# Compilamos el modelo con compile(). Aquí definimos la loss function, optimizer
# y métricas a calcular:

modelo %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0001, decay = 1e-6),
  metrics = "accuracy" )

summary(modelo)
```


```{r, cache = T}
# Entrenamos el modelo con fit():

set.seed(1)
start.time = Sys.time()

historial_entrenamiento_red_neuronal <- modelo %>% fit(
  x = dataset_guapo$train$x, y = dataset_guapo$train$y,
  batch_size = 32,
  epochs = 60,
  validation_data = list(dataset_guapo$test$x, dataset_guapo$test$y),
  shuffle = TRUE )

end.time = Sys.time() # Medimos tiempo que tarda en entrenarse la red

duracion_entrenamiento <- end.time-start.time

cat("El entrenamiento de la red neuronal ha tardado", duracion_entrenamiento)
```

```{r eval = F}
plot(historial_entrenamiento_red_neuronal)

# Si hubiésemos usado % split para validar la red, usaríamos este comando para
# evaluarla en el set de test

evaluacion <- evaluate(modelo, x=dataset_guapo$test$x, dataset_guapo$test$y, batch_size = 32, verbose = 1,
         sample_weight = NULL, steps = NULL)


cat("la red puede clasificar imagenes a color con una precisión en el set de evaluación del", historial_entrenamiento_red_neuronal$metrics$val_accuracy[40]*100, "% y una precisión en el set de test del", evaluacion[2]*100, "%.")
```

Por cierto, usé cuDNN 7.5.6 mientras compilaba este informe, y resulta que cada época de entrenamiento tardaba 13-14s (14s*60 épocas/ 60 segundos por minuto = 14 minutos).

Ahora con cuDNN 8.0.4 cada paso tarda 10 segundos = 10 mins.  He ahorrado 3 minutos por la jeta `r emo::ji("smile")` (O lo habría ahorrado si no estuviese haciendo otras cosas de mientras se entrena la red ¬¬).